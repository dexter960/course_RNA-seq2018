---
title: "Read counts to DGE, Part I"
output:
  html_document: default
  pdf_document: default
  toc: true
editor_options: 
  chunk_output_type: console
---

This script will show you how to:
 
* Read in `featureCounts` results into R.
* Use `DESeq2` to:
  - normalize read counts for sequencing depth
  - transform reads to the log2 scale
* Accompany each step by exploratory plots.

You can generate an html document out of this entire script by clickling the `Knit HTML` button in RStudio.

```{r settingUp, warning=FALSE, echo=TRUE, message=FALSE}
options(stringsAsFactors = FALSE) # this will change a global setting, but just for this session

library(knitr)
opts_chunk$set(echo = TRUE, message = FALSE,cache=FALSE) # tuning knitr output
```

## featureCounts

We aligned five samples for the WT and SNF2 condition, respectively.
You can find those files here: `~/mat/precomputed/results_alignment`.

>How can you check which command was used to generate those `BAM` files?

```{r featureCounts, eval=FALSE, echo = TRUE, engine='bash'}
mkdir class/read_counts
cd class/read_counts
REF_DIR=~/mat/referenceGenomes/S_cerevisiae/

 # reads for yeast samples counted on the meta-feature level
~/mat/software/subread-1.6.0-Linux-x86_64/bin/featureCounts \
	-a ${REF_DIR}/Saccharomyces_cerevisiae.R64-1-1.81.gtf \
	-o featCounts_genes.txt \
	 ~/mat/precomputed/results_alignment/*bam 
```

Let's read the result file into R, i.e. download the table from [our website](http://chagall.med.cornell.edu/RNASEQcourse/featureCounts_result.txt).

Loading additional libraries:

```{r}
library(ggplot2) # for making plots
library(magrittr) # for "pipe"-like coding in R
```

First, make sure you set the path to your working directory which should contain the count table.

```{r setWD}
folder <- "~/Documents/Teaching/2018_RNA-seq/" # download count table!
setwd(folder)
```

We will use the `DESeq2` package to normalize the samples for differences in their sequencing depth.

```{r install_bioconductor_pckgs, eval=FALSE, message = FALSE}
# not available via install.packages(), but through bioconductor
source("http://bioconductor.org/biocLite.R")
biocLite("DESeq2")
```

```{r warning=FALSE, message=FALSE}
library(DESeq2)
```

We will have to generate a `DESeqDataSet`; what is needed for this can be found 
out via `?DESeqDataSetFromMatrix`.
The help indicates that we need two tables: `countData` and `colData`.

* `colData`:  `data.frame` with all the variables you know about your samples, e.g., experimental condition, the type, and date of sequencing and so on. Its row.names should correspond to the unique sample names.
* `countData`: should contain a matrix of the actual values associated with the genes and samples. Is equivalent to `assay()`. Conveniently, this is almost exactly the format of the `featureCounts` output.

```{r reading_in}
folder <- "~/Documents/Teaching/2018_RNA-seq/"
# reading in featureCounts output
readcounts <- read.table(paste0(folder, "featCounts_genes.txt"),
                          header=TRUE)
head(readcounts)
```

__Preparing the count matrix for DESeq2:__

```{r countMatrix_prep}
# gene IDs should be stored as row.names
row.names(readcounts) <- gsub("-", ".", readcounts$Geneid)

# exclude the columns without read counts (columns 1 to 6 contain additional
# info such as genomic coordinates) 
readcounts <- readcounts[,-c(1:6)]

# give meaningful sample names - there are many ways to achieve this
orig_names <- names(readcounts)
names(readcounts) <- c("SNF2_1", "SNF2_2", "SNF2_3", "SNF2_4", "SNF2_5",
                        "WT_1", "WT_2", "WT_3", "WT_4", "WT_5" ) # most error-prone way!

# alternatives:
names(readcounts) <- c( paste("SNF2", c(1:5), sep = "_"),
                        paste("WT", c(1:5), sep = "_") ) # less potential for typos
names(readcounts) <- gsub(".*(WT|SNF2)(_[0-9]+).*", "\\1\\2", orig_names) # why is this a safer solution?
```

Always check your data set after you manipulated it!

```{r}
str(readcounts)
```

```{r}
head(readcounts)
```

In addition to the read counts, we need some more information about the samples.
According to `?colData`, this should be a `data.frame`, where the _rows_ directly
match the _columns_ of the count data.

Here's how this could be generated in `R` matching the `readcounts` `data.frame` we already have:

```{r making_colData}
sample_info <- DataFrame(condition = gsub("_[0-9]+", "", names(readcounts)),
                          row.names = names(readcounts) )
sample_info
```

```{r}
str(sample_info)
```

Let's generate the `DESeqDataSet`:

```{r DESeqDataSet, warning=FALSE}
DESeq.ds <- DESeqDataSetFromMatrix(countData = readcounts,
                              colData = sample_info,
                              design = ~ condition)
DESeq.ds
head(counts(DESeq.ds))
```

How many reads were counted for each sample ( = library sizes)?

```{r eval=TRUE, echo=TRUE}
colSums(counts(DESeq.ds))
```
```{r eval=TRUE, echo=TRUE}
colSums(counts(DESeq.ds)) %>% barplot
```

Remove genes with no reads.

```{r eval = TRUE}
keep_genes <- rowSums(counts(DESeq.ds)) > 0
dim(DESeq.ds)
```
```{r}
DESeq.ds <- DESeq.ds[ keep_genes, ]
dim(DESeq.ds)
```

```{r}
counts(DESeq.ds) %>% str
assay(DESeq.ds) %>% str
```

Now that we have the data, we can start using `DESeq`'s functions, e.g. `estimateSizeFactors()` for sequencing depth normalization.

```{r sizeFactors}
DESeq.ds <- estimateSizeFactors(DESeq.ds)
sizeFactors(DESeq.ds)
```

```{r sizeFactor_vs_librarySizes, eval=TRUE, echo=TRUE}
plot(sizeFactors(DESeq.ds), colSums(counts(DESeq.ds)))
```

The read counts normalized for sequencing depth can be accessed via `counts(..., normalized = TRUE)`.

Let's check whether the normalization helped adjust global differences between the samples.

```{r boxplots_untransformed, fig.width = 10, fig.height = 5}
# setting up the plotting layout
par(mfrow=c(1,2))
counts.sf_normalized <- counts(DESeq.ds, normalized=TRUE)

# adding the boxplots
boxplot(counts.sf_normalized, main = "SF normalized")
boxplot(counts(DESeq.ds), main = "read counts only")
```

We can't really see anything. 
It is usually helpful to *transform* the normalized read counts to bring them onto more similar scales.

>To see the influence of the sequencing depth normalization, make two box plots
of log2(read counts) - one for unnormalized counts, the other one for normalized
counts (exclude genes with zero reads in all samples).

```{r boxplots_logReadCounts, fig.width = 10, fig.height = 15}
par(mfrow=c(1,2)) # to plot the two box plots next to each other
boxplot(log.counts, notch=TRUE,
        main = "Non-normalized read counts\n(log-transformed)",
        ylab="read counts")
boxplot(log.norm.counts, notch=TRUE,
        main = "Size-factor-normalized read counts\n(log-transformed)",
        ylab="read counts") 
```

--------------------------------

## Day 4

### Understanding more properties of read count data

Characteristics we've touched upon so farL:

* zeros can mean two things: no expression or no detection
* fairly large dynamic range

>Make a scatterplot of log normalized counts against each other to see how well 
the actual values correlate which each other per sample and gene.

```{r}
load("~/Documents/Teaching/2018_RNA-seq/Rclass.RData")
library(magrittr)
library(ggplot2)
library(DESeq2)
```

```{r logReadCountTables}
# non-normalized read counts plus pseudocount
log.counts <- log2(counts(DESeq.ds, normalized = FALSE) + 1)
# instead of creating a new object, we could assign the values to a distinct matrix
# within the DESeq.ds object
assay(DESeq.ds, "log.counts") <- log.counts
# normalized read counts
log.norm.counts <- log2(counts(DESeq.ds, normalized=TRUE) + 1)
assay(DESeq.ds, "log.norm.counts") <- log.norm.counts
```

```{r scatterplots_logNormReadCounts, fig.width = 10, fig.height = 15}
par(mfrow=c(2,1)) 
DESeq.ds[, c("WT_1","WT_2")] %>% assay(.,  "log.norm.counts") %>% plot(., cex=.1, main = "WT_1 vs. WT_2")
DESeq.ds[, c("SNF2_1","SNF2_2")] %>% assay(.,  "log.norm.counts") %>% plot(., cex=.1, main = "SNF2_1 vs SNF2_2")
```

Every dot = one gene.

The fanning out of the points in the lower left corner (points below $2^5 = 32$) 
indicates that read counts correlate less well between replicates when they are low.

This observation indicates that the standard deviation of the expression levels 
may depend on the mean: the lower the mean read counts per gene, the higher the
standard deviation.

This can be assessed visually; the package `vsn` offers a simple function for this.

```{r vsn}
par(mfrow=c(1,1))
# generate the base meanSdPlot using sequencing depth normalized log2(read counts)
msd_plot <- vsn::meanSdPlot(log.norm.counts, 
                       ranks=FALSE, # show the data on the original scale
                       plot = FALSE)
msd_plot$gg + 
  ggtitle("Sequencing depth normalized log2(read counts)") +
  ylab("standard deviation") 
```

From the help for`meanSdPlot`: *The red dots depict the running median estimator* 
*(window-width 10 percent). If there is no variance-mean dependence, then the line*
*formed by the red dots should be approximately horizontal.*

The plot here shows that there is some variance-mean dependence for genes with 
low read counts.
This means that the data shows signs of _heteroskedasticity_.

Many tools expect data to be _homoskedastic_, i.e., all variables should have similar variances.

DESeq offers two ways to shrink the log-transformed counts for genes with very 
low counts: `rlog` and `varianceStabilizingTransformation` (`vst`).

We'll use `rlog` here as it is an optimized method for RNA-seq read counts:
it transforms the read counts to the log2 scale while simultaneously minimizing 
the difference between samples for rows with small counts and taking differences 
between library sizes of the samples into account.
`vst` tends to depend a bit more on the size factors, but generally, both methods
should return similar results.

```{r VarianceStabilization, fig.width = 15, fig.height = 8}
DESeq.rlog <- rlog(DESeq.ds, blind = TRUE) # this actually generates a different type of object
# set blind = FALSE if the conditions 
# are expected to introduce strong differences in a large proportion of the genes
```


```{r rlog_vs_log2, fig.width = 15, fig.height = 8}
par(mfrow=c(1,2)) 
plot(log.norm.counts[,1:2], cex=.1,
     main = "size factor and log2-transformed")

# the rlog-transformed counts are stored in the accessor "assay"
plot(assay(DESeq.rlog)[,1],
     assay(DESeq.rlog)[,2],
     cex=.1, main = "rlog transformed",
     xlab = colnames(assay(DESeq.rlog[,1])),
     ylab = colnames(assay(DESeq.rlog[,2])) )
rlog.norm.counts <- assay(DESeq.rlog)
```

As you can see in the left plot the variance - that is higher for small read 
counts - is tightened significantly using `rlog`.
What does the mean-sd-plot show?

```{r meanSdPlots, fig.width = 15, fig.height = 8}
# sequencing depth normalized log2(read counts)
msd_plot <- vsn::meanSdPlot(log.norm.counts, ranks=FALSE, plot = FALSE)
msd_plot$gg + ggtitle("Normal log transformation")

# rlog-transformed read counts
msd_plot <- vsn::meanSdPlot( rlog.norm.counts, ranks=FALSE, plot = FALSE)
msd_plot$gg + ggtitle("rlog transformation")
```

```{r, echo=TRUE, eval = FALSE}
save.image(file = "~/Documents/Teaching/2018_RNA-seq/Rclass.RData")
```

### Similarity assessments and clustering

`pcaExplorer` lets you interact with the DESeq2-based plots and analyses.
It has included hierarchical clustering of samples and PCA.

#### `pcaExplorer`

```{r eval=FALSE}
#source("https://bioconductor.org/biocLite.R")
#biocLite("pcaExplorer")
pcaExplorer::pcaExplorer(dds = DESeq.ds, rlt = DESeq.rlog)
```


#### Sample clustering using Pearson correlation

The ENCODE consortium recommends that _"for messenger RNA, (...) biological replicates [should] display greater than 0.9 correlation for transcripts/features"_.

The Pearson correlation coefficient is a measure of the strength of the linear relationship between two variables and is often used to assess the similarity of RNA-seq samples in a pair-wise fashion.
It is defined as the **covariance of two variables divided by the product of their standard deviation**.

Mimicking `pcaExplorer`'s heatmap:

```{r }
corr_coeff <- cor(rlog.norm.counts, method = "pearson")
as.dist(1-corr_coeff, upper = TRUE) %>%as.matrix %>% pheatmap::pheatmap(., main = "Pearson correlation")
```

Just plot the dendrogram, comparing the effects of the `rlog` transformation.

```{r fig.width=10, fig.height=5}
par(mfrow=c(1,2))
# Pearson corr. for rlog.norm values
as.dist(1 - corr_coeff) %>% hclust %>% plot( ., labels = colnames(rlog.norm.counts), main = "rlog transformed read counts")

# Pearson corr. for log.norm.values
as.dist( 1 - cor(log.norm.counts, method = "pearson")) %>% hclust %>% plot( ., labels = colnames(log.norm.counts), main = "no rlog")
```


#### How to do the PCA yourself (see the "protocol" part of pcaExplorer!)

```{r pca, eval=FALSE}
rv <- rowVars(assay(DESeq.rlog)) # equivalent to rowVars(rlog.norm.counts)
top_variable <- order(rv, decreasing = TRUE)[seq_len(500)]
pca <- prcomp(t(assay(DESeq.rlog)[top_variable, ]))
head(pca$x)
```


